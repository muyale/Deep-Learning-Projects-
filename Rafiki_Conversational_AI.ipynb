{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time  \n",
        "import torch\n",
        "import os\n",
        "from transformers import AutoTokenizer,AutoModelForCausalLM"
      ],
      "metadata": {
        "id": "2JaHsTJ-iTY3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ABOUT : RAFIKI\n",
        "\"\"\"The Idea behind this ChatBot is to create a virtual assistant or chatbot that a user can talk with.\n",
        "As we venture more into Artificial Intelligence there is going to be less and lesser interactions between humans.\n",
        "Virtual Assistants have already been deployed and are of importance .Examples include Siri,Alexa \n",
        "For my first ChatBot project I am going to build a general conversation type of AI using a pretrained Model.\n",
        "The Model(DialoGPT ) has been trained on over 147 millions conversations on Reddit and it has what many may term as \"cognitive\"\n",
        "Abilities to hold conversations.\n",
        "\n",
        "Lets Build Together :: \"\"\"\n",
        "        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "hIsyPMRB5CtV",
        "outputId": "83ead217-9798-4b13-98f4-49836b3615bd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Idea behind this ChatBot is to create a virtual assistant or chatbot that a user can talk with.\\nAs we venture more into Artificial Intelligence there is going to be less and lesser interactions between humans.\\nVirtual Assistants have already been deployed and are of importance .Examples include Siri,Alexa \\nFor my first ChatBot project I am going to build a general conversation type of AI using a pretrained Model.\\nThe Model(DialoGPT ) has been trained on over 147 millions conversations on Reddit and it has what many may term as \"cognitive\"\\nAbilities to hold conversations.\\n\\nLets Build Together :: '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGbBMwHBiK4e",
        "outputId": "b0ca5cb5-20bb-49f6-d351-94f21a30799d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"microsoft/DialoGPT-medium\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForCausalLM.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "Lzvi7zzgiv07"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QjFW4BPvwoi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a ChatBot class with all necessary modules to make a complete conversation\n",
        "class Rafiki_AI():\n",
        "    # initialize\n",
        "    def __init__(self):\n",
        "        # once chat starts, the history will be stored for chat continuity\n",
        "        self.chat_history_ids = None\n",
        "        # make input ids global to use them anywhere within the object\n",
        "        self.bot_input_ids = None\n",
        "        # a flag to check whether to end the conversation\n",
        "        self.end_chat = False\n",
        "        # greet while starting\n",
        "        self.welcome()\n",
        "        \n",
        "    def welcome(self):\n",
        "        print(\"Initializing Rafiki ...\")\n",
        "        # some time to get user ready\n",
        "        time.sleep(2)\n",
        "        print('Type \"bye\" or \"quit\" or \"exit\" to end chat \\n')\n",
        "        time.sleep(3)\n",
        "        # Greet and introduce\n",
        "        greeting = np.random.choice([\n",
        "            \"Welcome, I am Rafiki, here for your kind service\",\n",
        "            \"Hey, Great day! I am your virtual assistant:Rafiki\",\n",
        "            \"Hello, it's my pleasure meeting you\",\n",
        "            \"Hi, I am a Rafiki. Let's chat!\"\n",
        "        ])\n",
        "        print(\"Rafiki >>  \" + greeting)\n",
        "        \n",
        "    def user_input(self):\n",
        "        # receive input from user\n",
        "        text = input(\"User    >> \")\n",
        "        # end conversation if user wishes so\n",
        "        if text.lower().strip() in ['bye', 'quit', 'exit']:\n",
        "            # turn flag on \n",
        "            self.end_chat=True\n",
        "            # a closing comment\n",
        "            print('Rafiki >>  Tutaongea! Bye!')\n",
        "            time.sleep(1)\n",
        "            print('\\nQuitting Rafiki ...Asante Sana')\n",
        "        else:\n",
        "            # continue chat, preprocess input text\n",
        "            # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
        "            self.new_user_input_ids = tokenizer.encode(text + tokenizer.eos_token, \\\n",
        "                                                       return_tensors='pt')\n",
        "\n",
        "    def bot_response(self):\n",
        "        # append the new user input tokens to the chat history\n",
        "        # if chat has already begun\n",
        "        if self.chat_history_ids is not None:\n",
        "            self.bot_input_ids = torch.cat([self.chat_history_ids, self.new_user_input_ids], dim=-1) \n",
        "        else:\n",
        "            # if first entry, initialize bot_input_ids\n",
        "            self.bot_input_ids = self.new_user_input_ids\n",
        "        \n",
        "        # define the new chat_history_ids based on the previous chats\n",
        "        # generated a response while limiting the total chat history to 1000 tokens, \n",
        "        self.chat_history_ids = model.generate(self.bot_input_ids, max_length=1000, \\\n",
        "                                               pad_token_id=tokenizer.eos_token_id)\n",
        "            \n",
        "        # last ouput tokens from bot\n",
        "        response = tokenizer.decode(self.chat_history_ids[:, self.bot_input_ids.shape[-1]:][0], \\\n",
        "                               skip_special_tokens=True)\n",
        "        # in case, bot fails to answer\n",
        "        if response == \"\":\n",
        "            response = self.random_response()\n",
        "        # print bot response\n",
        "        print('Rafiki >>  '+ response)\n",
        "        \n",
        "    # in case there is no response from model\n",
        "    def random_response(self):\n",
        "        i = -1\n",
        "        response = tokenizer.decode(self.chat_history_ids[:, self.bot_input_ids.shape[i]:][0], \\\n",
        "                               skip_special_tokens=True)\n",
        "        # Reiterate backwards to find history\n",
        "        while response == '':\n",
        "            i = i-1\n",
        "            response = tokenizer.decode(self.chat_history_ids[:, self.bot_input_ids.shape[i]:][0], \\\n",
        "                               skip_special_tokens=True)\n",
        "        # For questions ,give answers\n",
        "        if response.strip() == '?':\n",
        "            reply = np.random.choice([\"I don't know\",\"I'll check\" \n",
        "                                     \"Sijui for Now\"])\n",
        "        # not a question? answer suitably\n",
        "        else:\n",
        "            reply = np.random.choice([\"Great\", \"Awesome\"\n",
        "                                      \"Fine. What's up?\", \n",
        "                                      \"Okay\"\n",
        "                                     ])\n",
        "        return reply"
      ],
      "metadata": {
        "id": "-ZfC0JVAzK1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bot = Rafiki_AI()\n",
        "# start chatting\n",
        "while True:\n",
        "    # receive user input\n",
        "    bot.user_input()\n",
        "    # check whether to end chat\n",
        "    if bot.end_chat:\n",
        "        break\n",
        "    # output bot response\n",
        "    bot.bot_response()    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCh96euuy6Xo",
        "outputId": "bc94014b-a7f3-4743-95eb-6249f2b5b053"
      },
      "execution_count": 30,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing Rafiki ...\n",
            "Type \"bye\" or \"quit\" or \"exit\" to end chat \n",
            "\n",
            "Rafiki >>  Welcome, I am Rafiki, here for your kind service\n",
            "User    >> Can we talk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rafiki >>  I'm not sure what you mean by that.\n",
            "User    >> Whats your favorite sport\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rafiki >>  I don't really watch sports.\n",
            "User    >> What do you watch then\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rafiki >>  I don't really watch sports.\n",
            "User    >> What is you favorite colour\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rafiki >>  I don't really watch sports.\n",
            "User    >> exit\n",
            "Rafiki >>  See you soon! Bye!\n",
            "\n",
            "Quitting Rafiki ...Asante Sana\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bot = Rafiki_AI()\n",
        "# start chatting\n",
        "while True:\n",
        "    # receive user input\n",
        "    bot.user_input()\n",
        "    # check whether to end chat\n",
        "    if bot.end_chat:\n",
        "        break\n",
        "    # output bot response\n",
        "    bot.bot_response()    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8aOpzuT4hfv",
        "outputId": "0f7373be-4720-4b6d-f481-0ece76e989b9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing Rafiki ...\n",
            "Type \"bye\" or \"quit\" or \"exit\" to end chat \n",
            "\n",
            "Rafiki >>  Hey, Great day! I am your virtual assistant:Rafiki\n",
            "User    >> Hi \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rafiki >>  Hey! :D\n",
            "User    >> How are you\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rafiki >>  I'm good, how are you?\n",
            "User    >> I am good too\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rafiki >>  I'm glad to hear that\n",
            "User    >> I feel sad\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rafiki >>  I feel sad too\n",
            "User    >> Why do you feel sad\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rafiki >>  I feel sad\n",
            "User    >> Change\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rafiki >>  I feel sad\n",
            "User    >> sorry\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rafiki >>  I feel sad\n",
            "User    >> exit\n",
            "Rafiki >>  See you soon! Bye!\n",
            "\n",
            "Quitting Rafiki ...Asante Sana\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Rafiki():\n",
        "  bot = Rafiki_AI()\n",
        "  # start chatting\n",
        "  while True:\n",
        "      # receive user input\n",
        "      bot.user_input()\n",
        "      # check whether to end chat\n",
        "      if bot.end_chat:\n",
        "          break\n",
        "      # output bot response\n",
        "      bot.bot_response()"
      ],
      "metadata": {
        "id": "41JCeBhT6lEd"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rafiki()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKAE4Qp87Ikk",
        "outputId": "f0c7ba18-fe07-425b-a10f-9b8a150bc827"
      },
      "execution_count": 37,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing Rafiki ...\n",
            "Type \"bye\" or \"quit\" or \"exit\" to end chat \n",
            "\n",
            "Rafiki >>  Hi, I am a Rafiki. Let's chat!\n",
            "User    >> Hello\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rafiki >>  Hello! :D\n",
            "User    >> Blender bot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rafiki >>  I'm not a bot.\n",
            "User    >> Can you sing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rafiki >>  I can sing.\n",
            "User    >> Who is Ed Sheeran\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rafiki >>  I am Ed Sheeran.\n",
            "User    >> scary is it\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rafiki >>  I am Ed Sheeran.\n",
            "User    >> exit\n",
            "Rafiki >>  See you soon! Bye!\n",
            "\n",
            "Quitting Rafiki ...Asante Sana\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gcGLIZMG7PgU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}