{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf2ebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn,Tensor\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from transformers import RobertaForMaskedLM,RobertaTokenizer,BertSquadForQuestionAnswering,BertTokenizer,BartForConditionalGeneration\n",
    "from transformers import BartTokenizer\n",
    "device = 'cuda' if torch.cuda.is_available else cpu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7fa75d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After a search at clinicaltrials.org here were the results for the drugs for intervention of HIV infections;\n",
    "import string as str\n",
    "candidate_drugs = ['efavirenz','tenofovir','abacavir','SP01A','Atorvastatin','Sorividine','Raltegravir']\n",
    "def extract_candidates():\n",
    "    for i in range(len(candidate_drugs)):\n",
    "        for drugs in candidate_drugs:\n",
    "            drugs = drugs.strip('')\n",
    "            drugs = drugs.lower()\n",
    "            return drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71465f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'efavirenz'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_candidates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfed4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The project is in such a way that the predictions scores are calculated on queries filtered by target tokens to score relevance\n",
    "checkpoint = 'RobertaLM'\n",
    "model = RobertaForMaskedLM.from_pretrained(checkpoint)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efa6dee6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12848\\2507719889.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Roberta Scores model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mclass\u001b[0m  \u001b[0mRobertaScore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \"\"\"Args :\n\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mThis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpretrained\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mintend\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdo\u001b[0m \u001b[0ma\u001b[0m \u001b[0msearch\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;32min\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mRoberta\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseq_score\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mThese\u001b[0m \u001b[0mare\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mefficacy\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mI\u001b[0m \u001b[0mused\u001b[0m \u001b[0msoftmax\u001b[0m \u001b[0msince\u001b[0m \u001b[0mit\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mbetween\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# Roberta Scores model \n",
    "class RobertaScore(nn.Module):\n",
    "    \"\"\"Args :\n",
    "    input-  the drugs under study \n",
    "    model - This is the pretrained model which we intend to do a search ,in this case the Roberta Model\n",
    "    score,seq_score - These are predictions scores and the efficacy scores. I used softmax since it returns values between 0 and 1\n",
    "    This function works in this way : A query is sent to the pretrained roberta model,using the target, prediction scores are calculated and returned as\n",
    "    probability scores.The scores are then used to score our drugs which we can then use in the drug discovery \n",
    "    \n",
    "    Returns :\n",
    "    scores,seq scores\n",
    "        \"\"\"\n",
    "        def __init__(self,model=model,dataset=None):\n",
    "            super().__init__()\n",
    "            self.outmodel = RobertaForMaskedLM.from_pretrained(model)\n",
    "        def forward(self,word_mask,word_id,target_mask,target_id):\n",
    "            m= nn.Softmax(dim=2)\n",
    "            output_embeds = self.outmodel(word_id,token_type_ids=None,attention_mask=word_mask)\n",
    "            soft_embeds = m(output_embeds[0])\n",
    "            seq_score = torch.sum(soft_embeds.detach()[:,:,target_id],dim=2)\n",
    "            score = torch.sum(seq_score,dim=1)\n",
    "            score = score/(np.count_nonzero(word_id)*np.count_nonzero(target_id))\n",
    "            return score,seq_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcf8e4f",
   "metadata": {},
   "source": [
    "Extractive Summarization\n",
    "Building on this idea of target query filtering on the Roberta Model ,For clarity on what we are aiming at I will use \n",
    "Text Summarization to highlight sections of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5094a97c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5428\\189652265.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mRobertaPassageScore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;31m# Here we will score a source phrase using the target phrase for a prediction score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRobertaPassageScore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRobertaForMaskedLM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class RobertaPassageScore(nn.Module):\n",
    "    # Here we will score a source phrase using the target phrase for a prediction score\n",
    "    def __init__(self,model=model,dataset=None):\n",
    "        super(RobertaPassageScore,self).__init__()\n",
    "        self.outmodel = RobertaForMaskedLM.from_pretrained(model)\n",
    "    def forward(self,word_id,word_mask,target_id,target_mask):\n",
    "        output_embeds = self.outmodel(word_id,token_type_ids=None,attention_mask=word_mask)\n",
    "        m = nn.Softmax(dim=2)\n",
    "        soft_embeds = m(output_embeds[0])\n",
    "        seq_score = torch.sum(output_embeds.detach()[:,:,target_id],dim=2)\n",
    "        score = torch.sum(seq_score,dim=1)\n",
    "        score = score/(np.count_nonzero(target_id)*np.count_nonzero(word_id))\n",
    "        return score,seq_score\n",
    "max_seq_len =128\n",
    "def convert_text_to_score_input(text):\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    # We will have to check if the lenght of the tokenized text is greater than the sequence lenght\n",
    "    # We will then use the text upto the maximum sequence lenght using indexing\n",
    "    if len(tokenized_text)>max_seq_len :\n",
    "        tokenized_text = tokenized_text[:max_seq_len]\n",
    "        # As with all pretrained LMs we have to convert all the tokenized text to ids ,then make them tensors\n",
    "        token_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        token_ids_tensor = torch.tensor(token_ids)\n",
    "        padding = [0]*max_seq_len-len(token_ids)\n",
    "        idxes = torch.arange(0,max_seq_len,out=torch.LongTensor(max_seq_len)).unsqueeze(dim=0)\n",
    "        mask = Variable((idxes<len(tokenized_text)).float())\n",
    "        return token_ids_tensor.unsqueeze(0),mask\n",
    "def convert_text_to_score_target(text):\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    return tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "model = RobertaPassageScore()\n",
    "text = 'efavirenz is used in the treatment of'\n",
    "targettext = 'efficacy'\n",
    "targets = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(targettext))\n",
    "targetinput,targetmask = convert_text_to_score_input(targettext)\n",
    "scoreinput,mask = convert_text_to_score_input(text.split('.')[0])\n",
    "score,seqscore = model(scoreinput,mask,targets,mask)\n",
    "\n",
    "text_scores = []\n",
    "for sent in text.split('.'):\n",
    "    score_input = convert_text_to_score_input(sent)\n",
    "    score,seqscores = model(score_input,mask,targets,mask)\n",
    "    textscores.append(score)\n",
    "    print(f\"Highscores for {text.split('.')[3:4],textscores[3:4]}\")\n",
    "detections = 'efavirenz is used in the treatment of '\n",
    "startends = []\n",
    "for detection in detections:\n",
    "    start,end = text.find(detection),text.find(detection)+len(detection)\n",
    "    startends.append(start,end)\n",
    "startends\n",
    "ents = []\n",
    "for idx in range(len(startends)):\n",
    "    ent['start'] =startends['idx'][0]\n",
    "    ent['end'] = startend['idx'][1]\n",
    "    ent['label'] = 'efficacy'\n",
    "    ents.append(ent)\n",
    "# Display the Texts or passage highlighting from the Numerous articles in Roberta \n",
    "ex =[{'text':text,\n",
    "     \"ents\":ents,\n",
    "     \"title\":'Study Of Efavirenz'}]\n",
    "spacy.displacy.render(ex,style=\"ent\",manual=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7d08f2",
   "metadata": {},
   "source": [
    "# FORWARD CHAINING ANALYSIS +PREDICTIVE MODEL:\n",
    "USING PREDICTION SCORES TO ESTIMATE WHICH DRUGS WILL PASS THE CLINICAL TRIALS AND CREATING A PREDICTIVE MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec0c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'clinical trial efficacy'\n",
    "target = convert_target_to_score_input(target)\n",
    "\n",
    "class RobertaScore(nn.Module):\n",
    "    def __init__(self,model=model,dataset = None):\n",
    "        super(RobertaScore,self).__init__()\n",
    "        self.outmodel = RobertaForMaskedLM.from_pretrained(model)\n",
    "    def forward(self,word_mask,word_id,target_mask,target_id):\n",
    "        m = nn.Softmax(dim=2)\n",
    "        output_embeds = self.outmodel(word_id,token_type_ids=None,attention_mask = word_mask)\n",
    "        soft_embeds = m(output_embeds[0])\n",
    "        seq_score = torch.sum(soft_embeds.detach()[:,:,target_id],dim=2)\n",
    "        score = torch.sum(seq_score,dim=1)\n",
    "        score = score/(np.count_nonzero(target_id)*np.count_nonzero(word_id))\n",
    "        return score,seq_score\n",
    "model=RobertaScore()\n",
    "# Creating a predictive model\n",
    "candidate_drugs = ['efavirenz','tenofovir','abacavir','SP01A','Atorvastatin','Sorividine','Raltegravir']\n",
    "drugresults ={}\n",
    "for drug in candidate_drugs:\n",
    "    for targ in targets:\n",
    "        text,target = drug,targ\n",
    "        score_input,mask = convert_text_to_score_input(text)\n",
    "        target = convert_text_to_score_target(target)\n",
    "        score,seqscore = model(score_input,mask,target,mask)\n",
    "        controlresults[drug]=score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e2c5ee",
   "metadata": {},
   "source": [
    "# THE END : Thank You"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e843fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
