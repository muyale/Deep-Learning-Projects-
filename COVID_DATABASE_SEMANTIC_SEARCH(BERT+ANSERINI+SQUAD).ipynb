{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4c545e0",
   "metadata": {},
   "source": [
    "# THE OBJECTIVE OF THIS PROJECT IS TO BUILD AN AI SEARCH ENGINE THAT QUERIES A DATABASE,FILTERS OUT THE RESULTS ANDRETURNS THE ANSWER BASED ON THE RELEVANCE\n",
    "\n",
    "#THE METHODS I WILL USE INCLUDE\n",
    "\n",
    "1.BERT TRANSFORMER \n",
    "2.BART FOR ABSTRACT SUMMARIZATION\n",
    "3.META PUB TO FIND PDFs WITH THE RESEARCH QUESTION\n",
    "4.GOOGLE UNIVERSAL SENTENCE ENCODER \n",
    "5.USING SEGMENT SCORES TO CHOOSE THE BEST ANSWERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5ed952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I will set some default parametres\n",
    "FIND_PDFS = True\n",
    "USE_SUMMARY = True\n",
    "SEARCH_PUBMED = True\n",
    "SEARCH_MEDXRIV = True\n",
    "# Find pdfs will be linked to Metapub,Use_summary will be used with transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b796b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (6) Could not resolve host: download.java.net\n",
      "'mv' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'update-alternatives' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'update-alternatives' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# I will download JDK and have it set up\n",
    "import os\n",
    "!curl -O https://download.java.net/java/GA/jdk11/9/GPL/openjdk-11.0.2_linux-x64_bin.tar.gz\n",
    "!mv openjdk-11.0.2_linux-x64_bin.tar.gz /usr/lib/jvm/; cd /usr/lib/jvm/; tar -zxvf openjdk-11.0.2_linux-x64_bin.tar.gz\n",
    "!update-alternatives --install /usr/bin/java java /usr/lib/jvm/jdk-11.0.2/bin/java 1\n",
    "!update-alternatives --set java /usr/lib/jvm/jdk-11.0.2/bin/java\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/jdk-11.0.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be22aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we will be using Anserini ,I will have to download pyserini ,an application for python and anserini\n",
    "!pip install pyserini\n",
    "from pyserini import pysearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd65671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lucene Database ,where we will get some of our data on the CORD 19 database\n",
    "!wget -O lucene.tar.gz https://www.dropbox.com/s/j55t617yhvmegy8/lucene-index-covid-2020-04-10.tar.gz\n",
    "!tar xvfz lucene.tar.gz\n",
    "minDate = '2020/04/09'\n",
    "luceneDir = 'lucene-index-covid-2020-04-10/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07fcd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use Google Universal Sentence Encoder ,I will use tensorflow and set it up\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "!curl -L \"https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed\" | tar -zxvC /kaggle/working//sentence_wise_email/module/module_useT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c129f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers for Pretrained Models and Abstractive Text Summarization\n",
    "# Bert -Squad Pretrained Model and Bart Text Sumarization- trained on cnn data\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering,BertTokenizer\n",
    "from transformers import BartForConditionalGeneration,BartTokenizer\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "\n",
    "QA_MODEL = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "QA_TOKENIZER = BertTokenizer('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "QA_MODEL.to(device)\n",
    "QA_MODEL.eval()\n",
    "\n",
    "if USE_SUMMARY :\n",
    "    SUMMARY_MODEL = BartForConditionalGeneration('bart-large-cnn')\n",
    "    SUMMARY_MODEL = BartTokenizer('bart-large-cnn')\n",
    "    SUMMARY_MODEL.to(device)\n",
    "    SUMMARY_MODEL.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dc6d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up FIND PDFs and BioPython before we query our data \n",
    "if FIND_PDFS:\n",
    "    !pip install metapub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b9e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biopython \n",
    "# The purpose of biopython is so that we could search the pubmed database if need be\n",
    "!pip install biopython \n",
    "from Bio import Entrez,Medline\n",
    "try :\n",
    "    from StringIO import StringIO\n",
    "except ImportError:\n",
    "    from io import StringIO\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf78f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next I will set up a sample question and some keywords\n",
    "question = \"What are the main symptoms of Covid-19 disease\"\n",
    "keywords  = \"COVID-19,symptoms,main\"\n",
    "# So we will use Pyserini to do a search on the Lucene database\n",
    "# We will then store the information in a dictionary \n",
    "# For each of our entries we will check for the abstracts and in a way remove them \n",
    "# We will then remain with only relevant data\n",
    "import json \n",
    "searcher = pysearch.SimpleSearcher(luceneDir)\n",
    "results  = searcher.search(question+\".\"+keywords)\n",
    "n_results = len(results)\n",
    "result_dict = {}\n",
    "for i in range(0,n_results):\n",
    "    doc_json = json.load(results[i].raw)\n",
    "    idx =str(results[i].docid)\n",
    "    result_dict [idx] = doc_json\n",
    "    result_dict[idx]['title'] = results[i].lucene_document.get(\"title\")\n",
    "    result_dict[idx]['authors'] = results[i].lucene_document.get(\"authors\")\n",
    "    result_dict[idx]['doi'] = results[i].lucene_document.get(\"doi\")\n",
    "    # We need to scrubb off some abstracts\n",
    "    for idx,v in result_dict.items():\n",
    "        abs_dirty = v['abstract']\n",
    "        v['abstract_paragraph'] =[]\n",
    "        v['abstract_full'] = ''\n",
    "        # Here I make an assumption that abstract paragraphs are actually lists\n",
    "        if abs_dirty:\n",
    "            if isinstance(abs_dirty,list):\n",
    "                for p in abs_dirty:\n",
    "                    v['abstract_paragraph'].append(p['text'])\n",
    "                    v['abstract_full'] +=p['text']+'\\n\\n'\n",
    "            if isinstance(abs_dirty,str):\n",
    "                v['abstract_paragraph'].append(abs_dirty)\n",
    "                v['abstract_full']+= abs_dirty+'\\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will create a function that reconstructs the text before we pass it to our BertModel\n",
    "# We first remove all the hasttags and then replace long commas with shorter ones\n",
    "def text_process(tokens,start=0,stop=1):\n",
    "    if ['SEP'] in tokens:\n",
    "        sepind =tokens.index(['SEP'])\n",
    "        tokens = tokens[sepind+1:]\n",
    "        txt = ''.join(token)\n",
    "        txt = txt.replace('##','')\n",
    "        txt = txt.replace(\"##\",'')\n",
    "        txt = txt.strip()\n",
    "        txt = \"\".join(txt.split())\n",
    "        txt = txt.replace(' ,',',')\n",
    "        txt = txt.replace(' .','.')\n",
    "        txt = txt.replace(' (','(')\n",
    "        txt = txt.replace(' )',')')\n",
    "        txt = txt.replace(' _','_')\n",
    "        txt_list = txt.split(',')\n",
    "        txt = ''\n",
    "        nTxtl = len(txt_list)\n",
    "        if nTxtl==1:\n",
    "            return txt_list[0]\n",
    "        new_list = []\n",
    "        for i,t in enumerate(txt_list):\n",
    "            if i<nTxtl-1:\n",
    "                if t[-1].isdigit() and txt_list[i+1][0].isdigit():\n",
    "                    new_list +=[t,',']\n",
    "                else :\n",
    "                    new_list +=[t,' ,']\n",
    "            else :\n",
    "                new_list+=[t]\n",
    "        return ''.join(new_list)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757611a9",
   "metadata": {},
   "source": [
    "# BERT PREDICTION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17b2243a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (774918465.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\EDGAR MUYALE DAVIES\\AppData\\Local\\Temp\\ipykernel_9768\\774918465.py\"\u001b[1;36m, line \u001b[1;32m14\u001b[0m\n\u001b[1;33m    ''.join(docsplit[quarter-int(nSearch_Words*overlapFac/2)]):quarter+int(quarter*overlapFac/2)]),\u001b[0m\n\u001b[1;37m                                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def BertSquadPrediction(document,question):\n",
    "    # Using BartTokenizer we will encode all the words and convert to tokens\n",
    "    # This function will have to rewrite the document into 250-300 pages with 50 overlaps on either end\n",
    "    nWords = len(document.split())\n",
    "    input_ids_all = QA_TOKENIZER.encode(question,document)\n",
    "    tokens_all =QA_TOKENIZER.convert_ids_to_tokens(input_ids_all)\n",
    "    overlapFac = 1.1\n",
    "    if len(input_ids_all)*overlapFac>2048:\n",
    "        nSearch_Words = int(np.ceil(nWords/5))\n",
    "        quarter = int(np.ceil(nWords/4))\n",
    "        docsplit = document.split()\n",
    "        doc_pieces = [''.join(docsplit[:int(nSearch_Words*overlapFac)]),\n",
    "                     ''.join(docsplit[quarter-int(nSearch_Words*overlapFac/2):quarter+int(quarter*overlapFac/2)]),\n",
    "                    ''.join(docsplit[quarter*3-int(nSearch_Words*overlapFac/2):quarter*3+int(quarter*overlapFac/2)]),\n",
    "                    ''.join(docsplit[-int(nSearch_Words*overlapFac/2):])]\n",
    "        input_ids = [QA_TOKENIZER.encode(question,dp)for dp in docpieces]\n",
    "    elif  len(input_ids_all)*overlapFac >1536:\n",
    "        nSearch_Words = int(np.ceil(nWords/4))\n",
    "        third = int(np.ceil(nWords/3))\n",
    "        docsplit = document.split()\n",
    "        doc_pieces = [''.join(docsplit[:int(nSearch_Words*overlapFac)]),\n",
    "                     ''.join(docsplit[third-int(nSearch_Words*overlapFac/2):third+int(nSearch_Words*overlapFac/2)]),\n",
    "                     ''.join(docsplit[third*2-int(nSearch_Words*overlapFac/2):third*2+int(nSearch_Words*overlapFac/2)]),\n",
    "                     ''.join(docsplit[-int(nSearch_Words*overlapFac)]:)]\n",
    "        input_ids = [QA_TOKENIZER.encode(question,dp)for dp in docpieces]\n",
    "    elif len(input_ids_all)*overlapFac >1024 :\n",
    "        nSearch_Words = int(np.ceil(nWords/3))\n",
    "        middle = int(np.ceil(nWords/2))\n",
    "        docsplit = document.split()\n",
    "        docpieces = [''.join(docsplit[:int(nSearch_Words*overlapFac)]),\n",
    "                    ''.join(docplit[middle-int(nSearch_Words*overlapFac/2):middle+int(nSearch_Words*overlapFac/2)]),\n",
    "                    ''.join(docsplit[-int(nSearch_Words*overlapFac):])]\n",
    "        input_ids = [QA_TOKENIZER.encode(question,dp)for dp in docpieces]\n",
    "    elif len(input_ids_all)*ovelapFac > 512 :\n",
    "        nSearch_Words = int(np.ceil(nWords/2))\n",
    "        docsplit = document.split()\n",
    "        docpieces  = [''.join(docsplit[:int(nSearch_Words*overlapFac)]),\n",
    "                     ''.join(docsplit[-int(nSearch_Words*overlapFac):])]\n",
    "        input_ids = [QA_TOKENIZER.encode(question,dp) for dp in docpieces]\n",
    "    else :\n",
    "        input_ids = input_ids_all\n",
    "    absTooLong = False\n",
    "    answers = []\n",
    "    cons = []\n",
    "    \n",
    "    for iptIds in input_ids :\n",
    "        tokens = QA_TOKENIZER.convert_ids_to_tokens(iptIds)\n",
    "        sep_index = iptIds.index(QA_TOKENIZER.sep_token_id)\n",
    "        num_seg_a = sep_index+1\n",
    "        num_seg_b = len(iptIds)-num_seg_a\n",
    "        segment_ids = [0]* num_seg_a + [1]*num_seg_b\n",
    "        n_ids = len(segment_ids)\n",
    "        if n_ids < 512 :\n",
    "            start_scores,end_scores = QA_MODEL(torch.tensor([iptIds]).to(device),\n",
    "                                               token_type_ids = torch.tensor([segment_ids]).to(device))\n",
    "        else :\n",
    "            # For those texts that have more than 512 words :\n",
    "            print(f'****Document is too long we consider {nWords} it has {n_ids}')\n",
    "            absTooLong =True  \n",
    "            start_scores,end_scores = QA_MODEL(torch.tensor(iptIds[:512]).to(device),\n",
    "                                               token_type_ids= torch.tensor(segment_ids[:512]).to(device))\n",
    "            # declare what start scores and end scores are\n",
    "            start_scores = [:1:-1]\n",
    "            end_scores = [:1:-1]\n",
    "            # We will be considering the highest scoring scores among a list of possible matches and then we return the top value\n",
    "            answer_start = torch.argmax(start_scores)\n",
    "            answer_end = torch.argmax(end_scores)\n",
    "            # The reason we add +2 on our stop is because we index everything upto -1\n",
    "            answer = text_process(tokens = tokens,start =answer_start,stop=answer_end+2)\n",
    "        if answer.startswith('. ') or answer.startswith(', '):\n",
    "            answer = answer[2:]\n",
    "            c = start_scores[0,answer_start].item()+end_scores[0,answer_end].item()\n",
    "            cons.append(c)\n",
    "        maxC = max(cons)\n",
    "        iMaxC =[i for i,j in enumerate(cons) if j == maxC][0]\n",
    "        confidence = cons[iMaxC]\n",
    "        answer = answers[iMaxC]\n",
    "        sep_index =tokens_all.index(['SEP'])\n",
    "        full_txt_token = tokens_all[sep_index+1:]\n",
    "        abs_returned = text_process(full_txt_tokens)\n",
    "        ans ={}\n",
    "        ans['answer'] = answer\n",
    "        if answer.startswith(['CLS']) or answer_end.item() <sep_index or answer.end_with(['SEP']):\n",
    "            ans['confidence'] = 1000000\n",
    "        else :\n",
    "            ans['confidence'] = confidence\n",
    "            ans['abstract_bert'] =abs_returned\n",
    "            ans['abs_too_long'] = absTooLong\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c485ccd8",
   "metadata": {},
   "source": [
    "# Open Domain QA on our Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929d44f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2457645645.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\EDGAR MUYALE DAVIES\\AppData\\Local\\Temp\\ipykernel_9768\\2457645645.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    def AbstractSearch(result_dict,question):\u001b[0m\n\u001b[1;37m                                             ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def AbstractSearch(result_dict,question):\n",
    "    abstractResults = {}\n",
    "    for k,v in tqdm(result_dict.items()):\n",
    "        abstract = v['abstract_full']\n",
    "        ans = BertSquadPrediction(abstract,question)\n",
    "        if ans['answer']:\n",
    "            confidence=ans['confidence']\n",
    "            abstractResults[confidence] ={}\n",
    "            abstractResults[confidence][answer] = ans['answer']\n",
    "            abstractResults[confidence]['abstract_bert'] = ans['abstract_bert']\n",
    "            abstractResults[confidence]['abs_too_long'] = ans['abs_too_long']\n",
    "            absractResult[confidence]['idx'] = k\n",
    "        Result_List = list(abstractResults.keys())\n",
    "        if Result_List:\n",
    "            maxScore = max(Result_List)\n",
    "            total =0.0\n",
    "            exp_score=[]\n",
    "            for c in Result_List:\n",
    "                s = np.exp(c-maxScore)\n",
    "                exp_scores.append(s)\n",
    "                total = sum(exp_scores)\n",
    "                \n",
    "        for i,c in enumerate(cList):\n",
    "            abstractResults [exp_scores[i]/total] = abstractResults.pop(c)\n",
    "        return abstractResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b052bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394e7065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
